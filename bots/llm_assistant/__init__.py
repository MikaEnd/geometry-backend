import os
import requests
from core.interfaces import BotHandler

class LLMHandler(BotHandler):
    def can_handle(self, task_description: str) -> bool:
        return True  # —Å—Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π fallback

    def handle(self, task_description: str) -> dict:
        api_key = os.getenv("LLM_API_KEY")
        url = os.getenv("LLM_API_URL")
        model = os.getenv("LLM_MODEL_NAME")

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, —Ç–æ—á–Ω–æ –∏ –≤ –¥—É—Ö–µ –ø—Ä–æ–µ–∫—Ç–∞."},
                {"role": "user", "content": task_description}
            ]
        }

        try:
            response = requests.post(url, json=payload, headers=headers, timeout=20)
            response.raise_for_status()
            result = response.json()
            answer = result["choices"][0]["message"]["content"]
            return {"result": f"ü§ñ –û—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞:\n{answer.strip()}"}
        except Exception as e:
            return {"error": f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI: {e}"}
